{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import numpy as ny\n",
    "import pandas as ps\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_evaluation(tp, tn, fp, fn, beta=1.0):\n",
    "\n",
    "   accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "   sensitivity = tp / (tp + fn)\n",
    "   specificity = tn / (fp + tn)\n",
    "   precision = tp / (tp + fp)\n",
    "   recall = sensitivity\n",
    "   f_score = ( (beta**2 + 1) * precision * recall) / (beta**2 * precision + recall)\n",
    "   auc = (sensitivity + specificity) / 2\n",
    "   youden = sensitivity - (1 - specificity)\n",
    "   p_plus = sensitivity / (1 - specificity)\n",
    "   p_minus = (1 - sensitivity) / specificity\n",
    "   dp = (ny.sqrt(3) / ny.pi) * (ny.log(sensitivity/(1 - sensitivity) + ny.log(specificity/(1 - specificity))))\n",
    "\n",
    "   result = {}\n",
    "   result[\"tp\"] = tp\n",
    "   result[\"tn\"] = tn\n",
    "   result[\"fp\"] = fp\n",
    "   result[\"fn\"] = fn\n",
    "   result[\"accuracy\"] = accuracy\n",
    "   result[\"sensitivity\"] = sensitivity\n",
    "   result[\"specificity\"] = specificity\n",
    "   result[\"precision\"] = precision\n",
    "   result[\"recall\"] = recall\n",
    "   result[\"f-score\"] = f_score\n",
    "   result[\"AUC\"] = auc\n",
    "   result[\"Youden\"] = youden\n",
    "   result[\"p+\"] = p_plus\n",
    "   result[\"p-\"] = p_minus\n",
    "   result[\"DP\"] = dp\n",
    "\n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "set = ps.read_csv(\"voice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.label = [1 if each == \"female\" else 0 for each in set.label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.473409</td>\n",
       "      <td>0.084125</td>\n",
       "      <td>0.060063</td>\n",
       "      <td>0.204956</td>\n",
       "      <td>0.254828</td>\n",
       "      <td>0.367853</td>\n",
       "      <td>0.208279</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>0.564526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.157706</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.981526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.505075</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.077635</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>0.246961</td>\n",
       "      <td>0.644279</td>\n",
       "      <td>0.483766</td>\n",
       "      <td>0.630964</td>\n",
       "      <td>0.591578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125828</td>\n",
       "      <td>0.287642</td>\n",
       "      <td>0.031140</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.056449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.179222</td>\n",
       "      <td>0.675536</td>\n",
       "      <td>0.102873</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>0.385912</td>\n",
       "      <td>0.457148</td>\n",
       "      <td>0.885255</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.442738</td>\n",
       "      <td>0.548382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179222</td>\n",
       "      <td>0.236945</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>0.954963</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.049885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.554611</td>\n",
       "      <td>0.587559</td>\n",
       "      <td>0.389906</td>\n",
       "      <td>0.715802</td>\n",
       "      <td>0.407358</td>\n",
       "      <td>0.031549</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.923261</td>\n",
       "      <td>0.856457</td>\n",
       "      <td>0.299565</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.183442</td>\n",
       "      <td>0.041287</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.065659</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.265043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452195</td>\n",
       "      <td>0.627209</td>\n",
       "      <td>0.454272</td>\n",
       "      <td>0.317627</td>\n",
       "      <td>0.707515</td>\n",
       "      <td>0.474474</td>\n",
       "      <td>0.027742</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.958736</td>\n",
       "      <td>0.926348</td>\n",
       "      <td>0.372362</td>\n",
       "      <td>0.452195</td>\n",
       "      <td>0.279190</td>\n",
       "      <td>0.036829</td>\n",
       "      <td>0.929285</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.250536</td>\n",
       "      <td>0.250715</td>\n",
       "      <td>0.223380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.436911</td>\n",
       "      <td>0.684871</td>\n",
       "      <td>0.570361</td>\n",
       "      <td>0.198513</td>\n",
       "      <td>0.686256</td>\n",
       "      <td>0.577704</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.921665</td>\n",
       "      <td>0.901057</td>\n",
       "      <td>0.717272</td>\n",
       "      <td>0.436911</td>\n",
       "      <td>0.698762</td>\n",
       "      <td>0.380813</td>\n",
       "      <td>0.904450</td>\n",
       "      <td>0.279703</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.192280</td>\n",
       "      <td>0.192418</td>\n",
       "      <td>0.173674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>0.362946</td>\n",
       "      <td>0.731172</td>\n",
       "      <td>0.262871</td>\n",
       "      <td>0.171937</td>\n",
       "      <td>0.702595</td>\n",
       "      <td>0.621185</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.912549</td>\n",
       "      <td>0.834545</td>\n",
       "      <td>0.048868</td>\n",
       "      <td>0.362946</td>\n",
       "      <td>0.732760</td>\n",
       "      <td>0.126776</td>\n",
       "      <td>0.981526</td>\n",
       "      <td>0.305791</td>\n",
       "      <td>0.075269</td>\n",
       "      <td>0.167977</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.298053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.484949</td>\n",
       "      <td>0.799042</td>\n",
       "      <td>0.690337</td>\n",
       "      <td>0.134329</td>\n",
       "      <td>0.786967</td>\n",
       "      <td>0.742124</td>\n",
       "      <td>0.050161</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.855587</td>\n",
       "      <td>0.765849</td>\n",
       "      <td>0.028592</td>\n",
       "      <td>0.484949</td>\n",
       "      <td>0.847759</td>\n",
       "      <td>0.153011</td>\n",
       "      <td>0.981526</td>\n",
       "      <td>0.164908</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.134024</td>\n",
       "      <td>0.134120</td>\n",
       "      <td>0.208885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>0.492516</td>\n",
       "      <td>0.745692</td>\n",
       "      <td>0.695311</td>\n",
       "      <td>0.175136</td>\n",
       "      <td>0.767804</td>\n",
       "      <td>0.681107</td>\n",
       "      <td>0.041908</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.870307</td>\n",
       "      <td>0.792241</td>\n",
       "      <td>0.757865</td>\n",
       "      <td>0.492516</td>\n",
       "      <td>0.641561</td>\n",
       "      <td>0.127158</td>\n",
       "      <td>0.834600</td>\n",
       "      <td>0.265621</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.164046</td>\n",
       "      <td>0.164163</td>\n",
       "      <td>0.333559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.595700</td>\n",
       "      <td>0.768964</td>\n",
       "      <td>0.687590</td>\n",
       "      <td>0.282629</td>\n",
       "      <td>0.901780</td>\n",
       "      <td>0.699289</td>\n",
       "      <td>0.045203</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.822610</td>\n",
       "      <td>0.700510</td>\n",
       "      <td>0.956078</td>\n",
       "      <td>0.595700</td>\n",
       "      <td>0.714235</td>\n",
       "      <td>0.270097</td>\n",
       "      <td>0.954963</td>\n",
       "      <td>0.074312</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.025018</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>0.375386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "0     0.096419  0.473409  0.084125  0.060063  0.204956  0.254828  0.367853   \n",
       "1     0.125828  0.505075  0.116900  0.077635  0.215683  0.246961  0.644279   \n",
       "2     0.179222  0.675536  0.102873  0.034284  0.385912  0.457148  0.885255   \n",
       "3     0.528261  0.554611  0.587559  0.389906  0.715802  0.407358  0.031549   \n",
       "4     0.452195  0.627209  0.454272  0.317627  0.707515  0.474474  0.027742   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3163  0.436911  0.684871  0.570361  0.198513  0.686256  0.577704  0.046854   \n",
       "3164  0.362946  0.731172  0.262871  0.171937  0.702595  0.621185  0.015961   \n",
       "3165  0.484949  0.799042  0.690337  0.134329  0.786967  0.742124  0.050161   \n",
       "3166  0.492516  0.745692  0.695311  0.175136  0.767804  0.681107  0.041908   \n",
       "3167  0.595700  0.768964  0.687590  0.282629  0.901780  0.699289  0.045203   \n",
       "\n",
       "          kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n",
       "0     0.208279  0.635798  0.564526  0.000000  0.096419  0.157706  0.030501   \n",
       "1     0.483766  0.630964  0.591578  0.000000  0.125828  0.287642  0.031140   \n",
       "2     0.782275  0.442738  0.548382  0.000000  0.179222  0.236945  0.030264   \n",
       "3     0.001613  0.923261  0.856457  0.299565  0.528261  0.183442  0.041287   \n",
       "4     0.001732  0.958736  0.926348  0.372362  0.452195  0.279190  0.036829   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3163  0.003489  0.921665  0.901057  0.717272  0.436911  0.698762  0.380813   \n",
       "3164  0.000333  0.912549  0.834545  0.048868  0.362946  0.732760  0.126776   \n",
       "3165  0.003469  0.855587  0.765849  0.028592  0.484949  0.847759  0.153011   \n",
       "3166  0.002539  0.870307  0.792241  0.757865  0.492516  0.641561  0.127158   \n",
       "3167  0.002830  0.822610  0.700510  0.956078  0.595700  0.714235  0.270097   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx  \n",
       "0     0.981526  0.000000  0.006452  0.000000  0.000000  0.000000  \n",
       "1     0.834600  0.000407  0.006452  0.002144  0.002146  0.056449  \n",
       "2     0.954963  0.000060  0.006452  0.000357  0.000358  0.049885  \n",
       "3     0.834600  0.065659  0.006452  0.025375  0.025393  0.265043  \n",
       "4     0.929285  0.238994  0.006452  0.250536  0.250715  0.223380  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "3163  0.904450  0.279703  0.006452  0.192280  0.192418  0.173674  \n",
       "3164  0.981526  0.305791  0.075269  0.167977  0.166667  0.298053  \n",
       "3165  0.981526  0.164908  0.006452  0.134024  0.134120  0.208885  \n",
       "3166  0.834600  0.265621  0.006452  0.164046  0.164163  0.333559  \n",
       "3167  0.954963  0.074312  0.006452  0.025018  0.025036  0.375386  \n",
       "\n",
       "[3168 rows x 20 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y =set.label.values\n",
    "X = set.drop(['label'],axis=1)\n",
    "x = (X -ny.min(X)) / (ny.max(X)-ny.min(X)). values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split (x,y,test_size=0.3,random_state = 30)\n",
    "nn = MLPClassifier(solver='sgd',activation= 'logistic',learning_rate_init=1,hidden_layer_sizes=(15,10))\n",
    "nn.fit (xtrain, ytrain)\n",
    "NN_f=nn.predict(xtest) \n",
    "conf = confusion_matrix(ytest, NN_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(nn, xtest, ytest)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9622140613247201"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = conf[1,1]\n",
    "FP = conf[0,1]\n",
    "TN = conf[0,0]\n",
    "FN = conf[1,0]\n",
    "NN_results = performance_evaluation(TP, TN, FP, FN)\n",
    "NN_results\n",
    "NN_results.get(\"Youden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
